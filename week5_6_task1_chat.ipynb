{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmZr2Pwo20qO/bu7m2Rl+y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Silfa2/nlpcc-ui-2025/blob/main/week5_6_task1_chat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tugas Gabungan Minggu 5 & 6: Aplikasi LLM Interaktif\n",
        "\n",
        "**Nama:** Silfa Wulandari\n",
        "\n",
        "**NPM:** 2206090192\n",
        "\n",
        "**Tugas 1: Aplikasi Obrolan LLM Sederhana**\n",
        "------\n",
        "\n",
        "## üéØ Objektif Tugas 1\n",
        "Membuat aplikasi obrolan dasar berbasis teks (command-line) yang interaktif menggunakan LLM (OpenAI API) untuk merespons input pengguna. Aplikasi ini akan didesain sebagai *multi-turn chat*, artinya ia akan mengingat konteks percakapan sebelumnya.\n",
        "\n",
        "## üìö Langkah Pengerjaan\n",
        "Notebook ini akan memandu langkah-langkah pembuatan aplikasi chat:\n",
        "1.  **Instalasi & Impor Library**: Menyiapkan semua paket Python yang dibutuhkan.\n",
        "2.  **Pengaturan Kunci API**: Mengambil kunci API OpenAI dengan aman menggunakan Colab Secrets.\n",
        "3.  **Inisialisasi Klien OpenAI**: Membuat objek klien untuk berinteraksi dengan API.\n",
        "4.  **Logika Inti Aplikasi Chat**:\n",
        "    *   Mendefinisikan fungsi untuk mengirim pesan dan menerima respons dari LLM.\n",
        "    *   Mengelola riwayat percakapan (*chat history*).\n",
        "    *   Membuat *loop* interaktif untuk pengguna.\n",
        "5.  **Menjalankan Aplikasi Chat**: Demonstrasi cara menjalankan aplikasi.\n",
        "6.  **Penjelasan & Contoh Interaksi**: Detail mengenai pilihan desain, model yang digunakan, dan contoh percakapan.\n",
        "\n"
      ],
      "metadata": {
        "id": "Nagf_jklMfnD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zI05Kd1iMU_T",
        "outputId": "c01460aa-2369-48f8-cfb6-6c96701b59e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Library OpenAI telah terinstal dan library lain telah diimpor!\n"
          ]
        }
      ],
      "source": [
        "# Tahap 1.1: Instalasi Library OpenAI\n",
        "# Kita gunakan '-q' (quiet) agar output instalasinya tidak terlalu ramai.\n",
        "!pip install openai -q\n",
        "\n",
        "# Tahap 1.2: Impor Library yang Dibutuhkan\n",
        "import openai # Library utama untuk OpenAI\n",
        "from google.colab import userdata # Untuk mengakses Colab Secrets (kunci API)\n",
        "import os # Berguna untuk alternatif manajemen kunci API jika tidak di Colab\n",
        "from IPython.display import display, Markdown # Untuk menampilkan output Markdown yang lebih cantik di Colab\n",
        "\n",
        "print(\"‚úÖ Library OpenAI telah terinstal dan library lain telah diimpor!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîë Tahap 2: Pengaturan Kunci API & Inisialisasi Klien OpenAI\n",
        "\n",
        "Untuk berinteraksi dengan API OpenAI, kita memerlukan kunci API. Kunci ini bersifat rahasia dan tidak boleh dibagikan atau ditulis langsung dalam kode (*hardcode*). Kita akan menggunakan fitur **Colab Secrets** untuk menyimpannya dengan aman.\n"
      ],
      "metadata": {
        "id": "35rGgk6gNCOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tahap 2.1: Mengambil Kunci API dari Colab Secrets\n",
        "try:\n",
        "    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')\n",
        "    if not OPENAI_API_KEY:\n",
        "        # Jika kunci ada tapi kosong\n",
        "        display(Markdown(\"‚ö†Ô∏è **Peringatan:** Kunci API 'openai_key' ditemukan di Colab Secrets, tetapi nilainya kosong. Harap periksa kembali.\"))\n",
        "        raise ValueError(\"Kunci API 'openai_key' kosong.\")\n",
        "    print(\"‚úÖ Kunci API OpenAI berhasil diambil dari Colab Secrets.\")\n",
        "\n",
        "except userdata.SecretNotFoundError:\n",
        "    display(Markdown(\"‚ùå **Error:** *Secret* 'openai_key' tidak ditemukan di Colab Secrets.\"))\n",
        "    display(Markdown(\"Silakan ikuti langkah-langkah di atas untuk menambahkan kunci API Anda. Tanpa kunci API, aplikasi tidak akan berfungsi.\"))\n",
        "    OPENAI_API_KEY = None # Set ke None agar langkah selanjutnya bisa mendeteksi\n",
        "except ValueError as ve:\n",
        "    # Ini akan menangkap error dari 'raise ValueError' di atas jika kunci kosong\n",
        "    OPENAI_API_KEY = None\n",
        "except Exception as e:\n",
        "    display(Markdown(f\"üö® **Error tak terduga saat mengambil kunci API:** {str(e)}\"))\n",
        "    OPENAI_API_KEY = None\n",
        "\n",
        "# Tahap 2.2: Inisialisasi Klien OpenAI\n",
        "# Hanya lanjutkan jika kunci API berhasil didapatkan\n",
        "if OPENAI_API_KEY:\n",
        "    try:\n",
        "        client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
        "        print(\"ü§ñ Klien OpenAI berhasil diinisialisasi!\")\n",
        "        display(Markdown(\"üéâ **Selamat! Klien OpenAI siap digunakan.** Kita bisa lanjut ke tahap berikutnya.\"))\n",
        "    except Exception as e:\n",
        "        display(Markdown(f\"üî• **Error saat inisialisasi klien OpenAI:** {str(e)}\"))\n",
        "        display(Markdown(\"Pastikan kunci API Anda valid dan memiliki akses ke model yang akan digunakan.\"))\n",
        "        client = None # Set client ke None jika inisialisasi gagal\n",
        "else:\n",
        "    display(Markdown(\"üî¥ **Klien OpenAI tidak dapat diinisialisasi karena kunci API tidak tersedia atau bermasalah.**\"))\n",
        "    client = None"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "id": "6gsrB27pNcXL",
        "outputId": "e98648ad-701a-4f92-eee8-b848edbcf92a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Kunci API OpenAI berhasil diambil dari Colab Secrets.\n",
            "ü§ñ Klien OpenAI berhasil diinisialisasi!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "üéâ **Selamat! Klien OpenAI siap digunakan.** Kita bisa lanjut ke tahap berikutnya."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üß† Tahap 3: Fungsi Inti Aplikasi Chat Multi-Turn\n",
        "\n",
        "Sekarang kita akan membangun \"otak\" dari chatbot kita. Kita akan membuat sebuah fungsi yang canggih untuk menangani percakapan multi-putaran (***multi-turn***). Ini berarti chatbot kita akan mengingat apa yang sudah kita bicarakan sebelumnya, membuat interaksi terasa lebih alami dan cerdas!\n",
        "\n",
        "Fungsi `chat_with_ai` akan melakukan hal berikut:\n",
        "1.  Menerima input dari pengguna.\n",
        "2.  Menambahkan input pengguna ke dalam riwayat percakapan.\n",
        "3.  Mengirim seluruh riwayat percakapan ke model LLM OpenAI.\n",
        "4.  Menerima balasan dari AI.\n",
        "5.  Menambahkan balasan AI ke riwayat percakapan.\n",
        "6.  Mengembalikan balasan AI untuk ditampilkan.\n",
        "\n",
        "Kita juga akan membuat fungsi `display_chat_bubble` untuk menampilkan pesan dengan gaya gelembung obrolan agar lebih menarik secara visual."
      ],
      "metadata": {
        "id": "B8VjYNZrNtRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tahap 3.1: Fungsi untuk menampilkan pesan dalam gelembung obrolan\n",
        "def display_chat_bubble(role, message, model_name=None):\n",
        "    \"\"\"Menampilkan pesan dengan gaya gelembung obrolan di Colab.\"\"\"\n",
        "    if role == \"user\":\n",
        "        bubble_style = \"background-color: #E1F5FE; color: #01579B; border-radius: 15px 15px 0 15px; padding: 10px 15px; margin: 5px 50px 5px 5px; max-width: 70%; float: left; clear: both; box-shadow: 2px 2px 5px rgba(0,0,0,0.1);\"\n",
        "        align_container = \"display: flex; justify-content: flex-start;\"\n",
        "        avatar = \"üë§\"\n",
        "        prefix = \"Anda\"\n",
        "    elif role == \"assistant\":\n",
        "        bubble_style = \"background-color: #FCE4EC; color: #880E4F; border-radius: 15px 15px 15px 0; padding: 10px 15px; margin: 5px 5px 5px 50px; max-width: 70%; float: right; clear: both; box-shadow: -2px 2px 5px rgba(0,0,0,0.1);\"\n",
        "        align_container = \"display: flex; justify-content: flex-end;\"\n",
        "        avatar = \"ü§ñ\"\n",
        "        prefix = f\"AI ({model_name})\" if model_name else \"AI\"\n",
        "    else: # system message or others\n",
        "        display(Markdown(f\"_{message}_\"))\n",
        "        return\n",
        "\n",
        "    # Membersihkan pesan dari karakter yang bisa mengganggu HTML\n",
        "    message_cleaned = message.replace(\"<\", \"<\").replace(\">\", \">\")\n",
        "    # Mengganti newline dengan <br> untuk HTML\n",
        "    message_html = message_cleaned.replace('\\n', '<br>')\n",
        "\n",
        "    html_output = f\"\"\"\n",
        "    <div style=\"{align_container}\">\n",
        "        <div style=\"{bubble_style}\">\n",
        "            <strong style=\"font-size: 0.9em;\">{avatar} {prefix}:</strong><br>\n",
        "            {message_html}\n",
        "        </div>\n",
        "    </div>\n",
        "    <div style=\"clear: both;\"></div>\n",
        "    \"\"\"\n",
        "    display(Markdown(html_output))\n",
        "\n",
        "# Tahap 3.2: Fungsi inti untuk berinteraksi dengan LLM (Multi-Turn)\n",
        "def chat_with_ai(user_input, chat_history, model_name=\"gpt-3.5-turbo\"):\n",
        "    \"\"\"\n",
        "    Mengirim input pengguna dan riwayat percakapan ke OpenAI API,\n",
        "    dan mengembalikan respons dari AI.\n",
        "    \"\"\"\n",
        "    if not client:\n",
        "        display(Markdown(\"üî• **Error:** Klien OpenAI tidak diinisialisasi. Fungsi chat tidak dapat berjalan.\"))\n",
        "        return \"Maaf, saya tidak bisa merespons saat ini karena ada masalah koneksi.\", chat_history\n",
        "\n",
        "    # Tambahkan pesan pengguna ke riwayat\n",
        "    chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "    # Menampilkan gelembung pesan pengguna\n",
        "    # display_chat_bubble(\"user\", user_input) # Kita akan panggil ini di loop utama\n",
        "\n",
        "    try:\n",
        "        # Kirim seluruh riwayat ke API\n",
        "        response = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=chat_history\n",
        "        )\n",
        "        ai_reply = response.choices[0].message.content\n",
        "\n",
        "        # Tambahkan balasan AI ke riwayat\n",
        "        chat_history.append({\"role\": \"assistant\", \"content\": ai_reply})\n",
        "\n",
        "        # Menampilkan gelembung pesan AI\n",
        "        # display_chat_bubble(\"assistant\", ai_reply, model_name) # Kita akan panggil ini di loop utama\n",
        "\n",
        "        return ai_reply, chat_history\n",
        "\n",
        "    except openai.APIError as e:\n",
        "        error_message = f\"üò• Maaf, terjadi kesalahan API OpenAI: {e}\"\n",
        "        display(Markdown(f\"<div style='color: red; border: 1px solid red; padding: 10px; border-radius: 5px;'>{error_message}</div>\"))\n",
        "        # Hapus pesan pengguna terakhir dari riwayat jika terjadi error, agar tidak dikirim ulang\n",
        "        if chat_history and chat_history[-1][\"role\"] == \"user\":\n",
        "            chat_history.pop()\n",
        "        return error_message, chat_history\n",
        "    except Exception as e:\n",
        "        error_message = f\"ü§Ø Aduh, ada error tak terduga: {e}\"\n",
        "        display(Markdown(f\"<div style='color: red; border: 1px solid red; padding: 10px; border-radius: 5px;'>{error_message}</div>\"))\n",
        "        if chat_history and chat_history[-1][\"role\"] == \"user\":\n",
        "            chat_history.pop()\n",
        "        return error_message, chat_history\n",
        "\n",
        "# Tes kecil untuk memastikan fungsi bisa di-define (tidak akan menghasilkan output chat)\n",
        "if client:\n",
        "    print(\"‚úÖ Fungsi `display_chat_bubble` dan `chat_with_ai` berhasil didefinisikan.\")\n",
        "    print(\"   Kita akan menggunakannya di tahap berikutnya untuk membuat loop interaktif.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Fungsi didefinisikan, tetapi klien OpenAI tidak siap. Aplikasi chat mungkin tidak berfungsi.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPAgOE53N1k5",
        "outputId": "98199a73-f380-4b97-b5d6-28d785410303"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fungsi `display_chat_bubble` dan `chat_with_ai` berhasil didefinisikan.\n",
            "   Kita akan menggunakannya di tahap berikutnya untuk membuat loop interaktif.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üí¨ Tahap 4: Loop Interaktif Aplikasi Chat\n",
        "\n",
        "Inilah saatnya menghidupkan chatbot kita! Kode di bawah ini akan menjalankan *loop* utama aplikasi:\n",
        "1.  **Inisialisasi Riwayat**: Kita mulai dengan riwayat percakapan kosong, namun kita akan menambahkan \"pesan sistem\" (*system message*) untuk memberi tahu AI bagaimana ia harus bersikap (misalnya, sebagai asisten yang membantu).\n",
        "2.  **Pilihan Model**: Anda bisa memilih model LLM yang ingin digunakan.\n",
        "3.  **Loop Utama**:\n",
        "    *   Program akan meminta Anda mengetikkan pesan.\n",
        "    *   Pesan Anda dan respons AI akan ditampilkan menggunakan `display_chat_bubble` yang sudah kita buat.\n",
        "    *   Ketik `exit` atau `quit` untuk mengakhiri percakapan.\n",
        "    *   Ada juga batasan sederhana pada panjang riwayat untuk mencegah penggunaan token yang berlebihan dalam sesi demo yang panjang."
      ],
      "metadata": {
        "id": "LJj32-lMN1OF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tahap 4.1: Inisialisasi dan Menjalankan Loop Chat Interaktif\n",
        "\n",
        "if not client:\n",
        "    display(Markdown(\"üî¥ **Tidak dapat menjalankan chat:** Klien OpenAI belum siap. Pastikan kunci API sudah benar dan klien terinisialisasi.\"))\n",
        "else:\n",
        "    display(Markdown(\"üöÄ **Aplikasi Chat Siap Dimulai!** üöÄ\"))\n",
        "    print(\"Ketik pesan Anda di bawah. Ketik 'exit' atau 'quit' untuk keluar.\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # --- PENTING: PILIH MODEL ANDA DI SINI ---\n",
        "    # Model yang direkomendasikan: \"gpt-3.5-turbo\" (cepat & hemat) atau \"gpt-4o\" (lebih canggih)\n",
        "    # Pastikan kunci API Anda memiliki akses ke model yang dipilih.\n",
        "\n",
        "\n",
        "    display(Markdown(f\"‚ÑπÔ∏è *Menggunakan model: **{chosen_model}***\"))\n",
        "\n",
        "    # Inisialisasi riwayat percakapan dengan pesan sistem\n",
        "    # Pesan sistem ini membantu mengatur perilaku AI.\n",
        "    chat_history = [\n",
        "        {\"role\": \"system\", \"content\": \"Kamu adalah AsistenAI yang cerdas, ramah, dan sangat membantu. Kamu mengingat percakapan sebelumnya untuk memberikan respons yang relevan.\"}\n",
        "    ]\n",
        "\n",
        "    # Menampilkan pesan sistem (opsional, bisa di-comment jika tidak ingin terlihat)\n",
        "    # display_chat_bubble(\"system\", chat_history[0][\"content\"])\n",
        "\n",
        "    MAX_HISTORY_LEN = 20 # Batasi riwayat menjadi N pesan terakhir (user + assistant) untuk efisiensi token\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            user_input = input(\"üë§ Anda: \")\n",
        "        except KeyboardInterrupt:\n",
        "            display(Markdown(\"\\nüëã Sesi chat dihentikan oleh pengguna. Sampai jumpa!\"))\n",
        "            break\n",
        "        except EOFError: # Terjadi jika input stream ditutup (misalnya di beberapa environment non-interaktif)\n",
        "            display(Markdown(\"\\nüëã Input stream berakhir. Sampai jumpa!\"))\n",
        "            break\n",
        "\n",
        "\n",
        "        if user_input.lower() in ['exit', 'quit']:\n",
        "            display(Markdown(\"üëã Terima kasih sudah mengobrol! Sampai jumpa lagi!\"))\n",
        "            break\n",
        "\n",
        "        if not user_input.strip():\n",
        "            display_chat_bubble(\"assistant\", \"Hmm, sepertinya Anda belum mengetik apa-apa. Ada yang bisa saya bantu?\", chosen_model)\n",
        "            continue\n",
        "\n",
        "        # Tampilkan pesan pengguna terlebih dahulu\n",
        "        display_chat_bubble(\"user\", user_input)\n",
        "\n",
        "        # Dapatkan respons dari AI\n",
        "        ai_response, chat_history = chat_with_ai(user_input, chat_history, model_name=chosen_model)\n",
        "\n",
        "        # Tampilkan respons AI\n",
        "        display_chat_bubble(\"assistant\", ai_response, chosen_model)\n",
        "\n",
        "        # Manajemen riwayat sederhana: simpan N interaksi terakhir (pesan sistem + N pasangan user-assistant)\n",
        "        # Ini untuk mencegah riwayat menjadi terlalu panjang dan mahal.\n",
        "        # Setiap interaksi = 1 pesan user + 1 pesan assistant = 2 item di list\n",
        "        # Jadi, jika MAX_HISTORY_LEN = 20, kita simpan 10 interaksi terakhir.\n",
        "        if len(chat_history) > (MAX_HISTORY_LEN * 2 + 1): # +1 untuk pesan sistem\n",
        "            display(Markdown(f\"<i>(Riwayat percakapan dipangkas untuk efisiensi. Menyimpan {MAX_HISTORY_LEN} interaksi terakhir...)</i>\"))\n",
        "            # Simpan pesan sistem, lalu N interaksi terakhir\n",
        "            chat_history = [chat_history[0]] + chat_history[-(MAX_HISTORY_LEN*2):]\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "    display(Markdown(\"üèÅ **Sesi Chat Selesai.**\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Xt02EYbtOQnD",
        "outputId": "72d6ac86-893a-4be4-f3b4-b5cf964480cb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "üöÄ **Aplikasi Chat Siap Dimulai!** üöÄ"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ketik pesan Anda di bawah. Ketik 'exit' atau 'quit' untuk keluar.\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "‚ÑπÔ∏è *Menggunakan model: **gpt-4o***"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üë§ Anda: hai\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n    <div style=\"display: flex; justify-content: flex-start;\">\n        <div style=\"background-color: #E1F5FE; color: #01579B; border-radius: 15px 15px 0 15px; padding: 10px 15px; margin: 5px 50px 5px 5px; max-width: 70%; float: left; clear: both; box-shadow: 2px 2px 5px rgba(0,0,0,0.1);\">\n            <strong style=\"font-size: 0.9em;\">üë§ Anda:</strong><br>\n            hai\n        </div>\n    </div>\n    <div style=\"clear: both;\"></div>\n    "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n    <div style=\"display: flex; justify-content: flex-end;\">\n        <div style=\"background-color: #FCE4EC; color: #880E4F; border-radius: 15px 15px 15px 0; padding: 10px 15px; margin: 5px 5px 5px 50px; max-width: 70%; float: right; clear: both; box-shadow: -2px 2px 5px rgba(0,0,0,0.1);\">\n            <strong style=\"font-size: 0.9em;\">ü§ñ AI (gpt-4o):</strong><br>\n            Hai! Apa kabar? Ada yang bisa saya bantu hari ini?\n        </div>\n    </div>\n    <div style=\"clear: both;\"></div>\n    "
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üë§ Anda: apa ibukota indonesia\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n    <div style=\"display: flex; justify-content: flex-start;\">\n        <div style=\"background-color: #E1F5FE; color: #01579B; border-radius: 15px 15px 0 15px; padding: 10px 15px; margin: 5px 50px 5px 5px; max-width: 70%; float: left; clear: both; box-shadow: 2px 2px 5px rgba(0,0,0,0.1);\">\n            <strong style=\"font-size: 0.9em;\">üë§ Anda:</strong><br>\n            apa ibukota indonesia\n        </div>\n    </div>\n    <div style=\"clear: both;\"></div>\n    "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n    <div style=\"display: flex; justify-content: flex-end;\">\n        <div style=\"background-color: #FCE4EC; color: #880E4F; border-radius: 15px 15px 15px 0; padding: 10px 15px; margin: 5px 5px 5px 50px; max-width: 70%; float: right; clear: both; box-shadow: -2px 2px 5px rgba(0,0,0,0.1);\">\n            <strong style=\"font-size: 0.9em;\">ü§ñ AI (gpt-4o):</strong><br>\n            Ibu kota Indonesia adalah Jakarta. Ada yang lain yang ingin Anda ketahui?\n        </div>\n    </div>\n    <div style=\"clear: both;\"></div>\n    "
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üë§ Anda: tanggal ulang tahun jakarta kapan ya\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n    <div style=\"display: flex; justify-content: flex-start;\">\n        <div style=\"background-color: #E1F5FE; color: #01579B; border-radius: 15px 15px 0 15px; padding: 10px 15px; margin: 5px 50px 5px 5px; max-width: 70%; float: left; clear: both; box-shadow: 2px 2px 5px rgba(0,0,0,0.1);\">\n            <strong style=\"font-size: 0.9em;\">üë§ Anda:</strong><br>\n            tanggal ulang tahun jakarta kapan ya\n        </div>\n    </div>\n    <div style=\"clear: both;\"></div>\n    "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n    <div style=\"display: flex; justify-content: flex-end;\">\n        <div style=\"background-color: #FCE4EC; color: #880E4F; border-radius: 15px 15px 15px 0; padding: 10px 15px; margin: 5px 5px 5px 50px; max-width: 70%; float: right; clear: both; box-shadow: -2px 2px 5px rgba(0,0,0,0.1);\">\n            <strong style=\"font-size: 0.9em;\">ü§ñ AI (gpt-4o):</strong><br>\n            Jakarta merayakan hari ulang tahunnya pada tanggal 22 Juni. Tanggal ini dipilih berdasarkan penetapan Fatahillah atas nama Kerajaan Demak ketika berhasil merebut Sunda Kelapa dari Portugis pada 22 Juni 1527. Ada yang lain yang ingin Anda ketahui tentang Jakarta?\n        </div>\n    </div>\n    <div style=\"clear: both;\"></div>\n    "
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üë§ Anda: exit\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "üëã Terima kasih sudah mengobrol! Sampai jumpa lagi!"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "üèÅ **Sesi Chat Selesai.**"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚öôÔ∏è Tahap 5: Penjelasan Aplikasi Chat & Contoh Interaksi\n",
        "\n",
        "### Deskripsi Aplikasi\n",
        "Aplikasi ini adalah sebuah chatbot sederhana berbasis teks yang berinteraksi dengan pengguna melalui *command-line interface* di Google Colab. Chatbot ini menggunakan API dari OpenAI untuk menghasilkan respons berdasarkan input pengguna.\n",
        "\n",
        "### Fitur Utama & Pilihan Desain\n",
        "1.  **Interaksi Programatik dengan LLM**:\n",
        "    *   Aplikasi menggunakan *library* `openai` untuk mengirim permintaan ke model LLM.\n",
        "    *   Model yang digunakan saat ini adalah **`gpt-4o`** (Anda bisa menggantinya di kode jika diperlukan, misalnya ke `gpt-3.5-turbo` untuk efisiensi atau model lain yang didukung kunci API Anda). Model `gpt-4o` dipilih karena kemampuannya yang canggih dalam memahami konteks dan menghasilkan respons yang alami.\n",
        "2.  **Antarmuka Pengguna**:\n",
        "    *   Interaksi dilakukan melalui input teks standar di sel Colab.\n",
        "    *   Respons dari pengguna dan AI ditampilkan dengan gaya \"gelembung obrolan\" menggunakan HTML dan Markdown di output sel Colab untuk visualisasi yang lebih baik.\n",
        "3.  **Fungsionalitas Multi-Turn**:\n",
        "    *   Aplikasi ini dirancang sebagai *multi-turn chat*. Ini berarti ia **mengingat riwayat percakapan** sebelumnya.\n",
        "    *   Setiap kali pengguna mengirim pesan baru, seluruh riwayat percakapan (termasuk pesan sistem awal yang mengatur perilaku AI) dikirimkan ke LLM. Hal ini memungkinkan AI memberikan respons yang lebih kontekstual dan relevan.\n",
        "    *   Terdapat mekanisme sederhana untuk membatasi panjang riwayat yang dikirim ke API (`MAX_HISTORY_LEN`) untuk mengelola penggunaan token dan biaya, terutama dalam sesi demo yang panjang.\n",
        "4.  **Pesan Sistem (System Message)**:\n",
        "    *   Sebuah pesan sistem awal (\"*Kamu adalah AsistenAI yang cerdas, ramah, dan sangat membantu. Kamu mengingat percakapan sebelumnya untuk memberikan respons yang relevan.*\") digunakan untuk memberikan instruksi awal kepada LLM mengenai persona dan perilakunya.\n",
        "5.  **Penanganan Input & Output**:\n",
        "    *   Pengguna dapat mengetik `exit` atau `quit` untuk mengakhiri sesi chat.\n",
        "    *   Input kosong dari pengguna akan ditangani dengan respons default dari AI.\n",
        "    *   Ada penanganan error dasar untuk masalah API atau error tak terduga lainnya.\n",
        "\n",
        "### Cara Menjalankan Aplikasi\n",
        "1.  Pastikan Anda telah menambahkan kunci API OpenAI Anda ke Colab Secrets dengan nama `openai_key`.\n",
        "2.  Jalankan semua sel kode dari Tahap 1 hingga Tahap 3.\n",
        "3.  Jalankan sel kode di Tahap 4 yang berisi *loop* interaktif.\n",
        "4.  Ketik pesan Anda pada *prompt* `üë§ Anda:` dan tekan Enter.\n",
        "5.  Untuk keluar, ketik `exit` atau `quit`.\n",
        "\n",
        "### Contoh Interaksi\n",
        "Berikut adalah contoh log percakapan dengan chatbot:\n",
        "\n",
        "```text\n",
        "üöÄ Aplikasi Chat Siap Dimulai! üöÄ\n",
        "Ketik pesan Anda di bawah. Ketik 'exit' atau 'quit' untuk keluar.\n",
        "--------------------------------------------------\n",
        "‚ÑπÔ∏è Menggunakan model: *gpt-4o*\n",
        "\n",
        "üë§ Anda: hai\n",
        "ü§ñ AI (gpt-4o): Hai! Apa kabar? Ada yang bisa saya bantu hari ini?\n",
        "\n",
        "üë§ Anda: apa ibukota indonesia\n",
        "ü§ñ AI (gpt-4o): Ibu kota Indonesia adalah Jakarta. Ada yang lain yang ingin Anda ketahui?\n",
        "\n",
        "üë§ Anda: tanggal ulang tahun jakarta kapan ya\n",
        "ü§ñ AI (gpt-4o): Jakarta merayakan hari ulang tahunnya pada tanggal 22 Juni. Tanggal ini dipilih berdasarkan penetapan Fatahillah atas nama Kerajaan Demak ketika berhasil merebut Sunda Kelapa dari Portugis pada 22 Juni 1527. Ada yang lain yang ingin Anda ketahui tentang Jakarta?\n",
        "\n",
        "üë§ Anda: exit\n",
        "üëã Terima kasih sudah mengobrol! Sampai jumpa lagi!\n",
        "--------------------------------------------------\n",
        "üèÅ Sesi Chat Selesai."
      ],
      "metadata": {
        "id": "S-uOibNKPcoN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Kesimpulan Tugas 1**\n",
        "\n",
        "Penyelesaian Tugas 1 ini berhasil mendemonstrasikan kemampuan dasar dalam membangun aplikasi chat interaktif menggunakan Model Bahasa Skala Besar (LLM) dari OpenAI. Berikut adalah beberapa poin refleksi dan kesimpulan:\n",
        "\n",
        "1.  **Keberhasilan Implementasi Inti**:\n",
        "    *   Aplikasi berhasil mengimplementasikan interaksi programatik dengan API OpenAI, memungkinkan dialog antara pengguna dan LLM. Penggunaan model `gpt-4o` (atau model pilihan Anda) menunjukkan kemampuan untuk memanfaatkan model yang canggih untuk pemahaman bahasa alami dan generasi respons.\n",
        "    *   Fitur *multi-turn chat*, yang dicapai dengan mengirimkan riwayat percakapan (`chat_history`) secara berkelanjutan, terbukti krusial. Tanpa ini, setiap interaksi akan terisolasi, mengurangi kemampuan chatbot untuk menjawab pertanyaan lanjutan atau merujuk pada konteks sebelumnya. Ini adalah perbedaan fundamental antara chatbot sederhana dan agen percakapan yang lebih cerdas.\n",
        "\n",
        "2.  **Peningkatan Pengalaman Pengguna**:\n",
        "    *   Visualisasi percakapan menggunakan \"gelembung obrolan\" (`display_chat_bubble`) secara signifikan meningkatkan keterbacaan dan pengalaman pengguna di lingkungan Colab, membuatnya lebih mirip dengan antarmuka chat modern.\n",
        "    *   Pesan sistem awal memberikan arahan yang berguna bagi LLM untuk mengadopsi persona sebagai \"AsistenAI yang cerdas, ramah, dan sangat membantu,\" yang berkontribusi pada kualitas dan gaya respons yang dihasilkan.\n",
        "\n",
        "3.  **Keterbatasan dan Potensi Pengembangan Lebih Lanjut**:\n",
        "    *   **Integrasi Alat (Tool Use)**: Chatbot saat ini murni berbasis teks. Untuk kemampuan yang lebih luas (misalnya, mengambil informasi *real-time*, melakukan kalkulasi), integrasi dengan alat eksternal melalui *function calling* (seperti yang akan dieksplorasi di Tugas Bonus) akan menjadi langkah berikutnya yang signifikan.\n",
        "    *   **Evaluasi Kualitas**: Kualitas respons chatbot saat ini dinilai secara subjektif. Dalam pengembangan yang lebih serius, metrik evaluasi formal (misalnya, BLEU, ROUGE untuk tugas tertentu, atau evaluasi manusia terstruktur) akan diperlukan.\n",
        "\n",
        "4.  **Pertimbangan Etis dan Biaya**:\n",
        "    *   Penggunaan model LLM canggih seperti `gpt-4o` memberikan respons berkualitas tinggi, namun juga datang dengan biaya API yang lebih tinggi per token dibandingkan model seperti `gpt-3.5-turbo`. Pemilihan model harus selalu mempertimbangkan keseimbangan antara kualitas, biaya, dan latensi.\n",
        "    *   Penting untuk selalu sadar akan potensi bias dalam data pelatihan LLM yang dapat muncul dalam respons, serta memastikan penggunaan AI yang bertanggung jawab.\n",
        "\n"
      ],
      "metadata": {
        "id": "p3RA-a4EQm48"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚ú® Tugas Bonus: Interaksi Multi-Modal - Memproses Gambar dan perlu disesuaikan untuk menyertakan gambar. Formatnya berbeda dari pesan teks murni. Biasanya melibatkan array `content` yang berisi Teks ‚ú®\n",
        "\n",
        "Untuk tugas bonus ini, saya memilih untuk mengimplementasikan fitur **Interaksi Multi-Modal** pada objek untuk teks dan objek untuk gambar (URL atau base64).\n",
        "\n",
        "3.  **Pemilihan Model yang T aplikasi chat Tugas 1. Secara spesifik, saya akan meningkatkan chatbot agar dapat:\n",
        "\n",
        "üéØ **Menerima inputepat:**\n",
        "    *   Anda **harus** menggunakan model yang mendukung input visual, seperti `gpt-4o gambar dari pengguna bersama dengan kueri teks, dan meminta LLM untuk memproses serta merespons berdasarkan kedua jenis` atau `gpt-4-vision-preview` (jika menggunakan OpenAI). Model seperti `gpt-3.5-turbo input tersebut.**\n",
        "\n",
        "**Alasan Pemilihan Fitur:**\n",
        "1.  **Relevansi dengan Kemajuan AI Ter` tidak bisa memproses gambar. Pastikan `chosen_model` diatur dengan benar.\n",
        "\n",
        "4.  **Penjelasan Markdown untuk Bonus:**\n",
        "    *   Tambahkan bagian baru di *notebook* Tugas 1 khusus untuk menjelaskan fitur bonuskini**: Model multi-modal yang dapat memahami dan berinteraksi dengan berbagai jenis data (teks, gambar, ini, termasuk:\n",
        "        *   Mengapa Anda memilih fitur ini.\n",
        "        *   Bagaimana Anda mengintegrasikannya ( audio) merupakan salah satu ranah paling menarik dan berkembang pesat dalam AI generatif. Mengimplementasikan ini menunjukkan pemperubahan kode utama).\n",
        "        *   Demonstrasi cara kerjanya (contoh input dengan URL gambar dan pertanyaanahaman terhadap kapabilitas model terkini.\n",
        "2.  **Peningkatan Signifikan pada Aplikasi Chat**: Kemampuan untuk membahas, serta respons LLM).\n",
        "        *   Tantangan yang mungkin dihadapi.\n",
        "\n",
        "---\n",
        "\n",
        "**Mari kita gambar secara langsung dalam percakapan membuka berbagai kasus penggunaan baru dan membuat interaksi jauh lebih kaya dan intuitif, mel mulai dengan modifikasi kode. Kita akan fokus pada notebook `week5_6_task1_chat.ipynb`.ampaui batasan teks murni. Pengguna bisa bertanya tentang objek dalam gambar, meminta deskripsi, atau bahkan**\n",
        "\n",
        "**Tahap Bonus 1: Modifikasi Fungsi `chat_with_ai` dan Persiapan Input Gambar meminta interpretasi kreatif.\n",
        "3.  **Demonstrasi Pemahaman API Multi-Modal**: Implementasi ini memerlukan pem**\n",
        "\n",
        "Kita akan memperbarui fungsi `chat_with_ai` dan sedikit mengubah loop utama untuk menangani input gambar.\n",
        "\n",
        "**ahaman tentang bagaimana mengirim data gambar (misalnya, sebagai URL atau base64) dan teks secara bersamaan ke *Di notebook `week5_6_task1_chat.ipynb` Anda:**\n",
        "\n",
        "1.  **Pastikan Modelendpoint* API LLM yang mendukung multi-modal (seperti `gpt-4o` atau model Vision lainnya).\n",
        "4. yang Dipilih Mendukung Vision:**\n",
        "    Di sel kode Tahap 4 (Loop Interaktif Aplikasi Chat), pastikan  **Potensi Dampak yang Jelas**: Manfaat fitur ini mudah didemonstrasikan dan dipahami. Misalnya `chosen_model` diatur ke model yang mendukung visi. `gpt-4o` adalah pilihan yang baik.\n",
        "    ```, pengguna mengunggah gambar kucing dan bertanya, \"Jenis kucing apa ini dan apa yang sedang dilakukannya?\" LLM kemudianpython\n",
        "    # chosen_model = \"gpt-3.5-turbo\" # GANTI INI\n",
        "    chosen_model = \"gpt-4o\" # Model ini mendukung teks dan gambar\n",
        "    ```\n",
        "\n",
        "2.  **Modifikasi akan merespons berdasarkan analisis gambar dan teks.\n",
        "\n",
        "Fitur ini akan diintegrasikan ke dalam loop chat yang sudah ada, Fungsi `chat_with_ai` (dari Tahap 3 di Tugas 1):**\n",
        "    Ganti dengan modifikasi pada cara pengguna memberikan input dan bagaimana pesan dikonstruksi untuk dikirim ke LLM. Model yang akan definisi fungsi `chat_with_ai` Anda dengan yang berikut. Perhatikan perubahan pada parameter dan cara `messages` dibuat ditargetkan untuk fitur ini adalah `gpt-4o` karena dukungannya yang kuat untuk input multi-modal."
      ],
      "metadata": {
        "id": "MNPgaUYb23Qt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tahap Bonus A.1: Fungsi untuk Encoding Gambar ke Base64\n",
        "import base64\n",
        "import mimetypes # Untuk mendapatkan tipe MIME gambar\n",
        "\n",
        "def image_to_base64(image_bytes, mime_type=None):\n",
        "    \"\"\"Mengonversi byte gambar ke string data URI base64.\"\"\"\n",
        "    if not mime_type:\n",
        "        # Jika tipe MIME tidak disediakan, coba tebak (ini mungkin tidak selalu akurat)\n",
        "        # Untuk penggunaan yang lebih robust, sebaiknya ketahui tipe MIME dari file asli\n",
        "        # Namun, untuk banyak format umum (jpg, png), ini seringkali cukup.\n",
        "        # Kita akan asumsikan PNG atau JPEG jika tidak diketahui, tapi ini bisa disempurnakan.\n",
        "        # Untuk Colab files.upload(), kita tidak langsung dapat nama file asli di sini.\n",
        "        # Jadi, kita akan mengandalkan input mime_type atau default ke format umum.\n",
        "        # Jika Anda tahu nama file, Anda bisa menggunakan:\n",
        "        # mime_type, _ = mimetypes.guess_type(file_path)\n",
        "        # Jika tidak, kita bisa coba default ke 'image/png' atau 'image/jpeg'\n",
        "        # atau biarkan API LLM yang mencoba menentukannya jika format base64 saja cukup.\n",
        "        # Untuk OpenAI, menyertakan tipe MIME di data URI adalah praktik terbaik.\n",
        "        # Kita akan coba default ke png jika tidak ada.\n",
        "        mime_type = \"image/png\" # Default jika tidak ada info\n",
        "\n",
        "    base64_encoded_data = base64.b64encode(image_bytes).decode('utf-8')\n",
        "    return f\"data:{mime_type};base64,{base64_encoded_data}\"\n",
        "\n",
        "print(\"‚úÖ Fungsi image_to_base64 siap digunakan.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6Tddhj53P6a",
        "outputId": "25b47d9c-a0b0-4429-b06d-e4db45360017"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fungsi image_to_base64 siap digunakan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tahap Bonus A.2: Fungsi Chat Multi-Modal (Teks + Gambar)\n",
        "# Ini adalah versi modifikasi dari fungsi chat_with_ai sebelumnya\n",
        "\n",
        "def chat_with_ai_multimodal(user_text_input, chat_history, image_base64_data_uri=None, model_name=\"gpt-4o\"):\n",
        "    \"\"\"\n",
        "    Mengirim input pengguna (teks dan/atau gambar base64) dan riwayat percakapan\n",
        "    ke API OpenAI, dan mengembalikan respons dari AI.\n",
        "    Riwayat chat_history diasumsikan hanya berisi pesan teks untuk kesederhanaan saat ini.\n",
        "    \"\"\"\n",
        "    if not client:\n",
        "        error_msg = \"‚ùå Klien OpenAI tidak diinisialisasi. Fungsi chat multi-modal tidak dapat berjalan.\"\n",
        "        display(Markdown(f\"<div style='color: red; border: 1px solid red; padding: 10px; border-radius: 5px;'>{error_msg}</div>\"))\n",
        "        # Kembalikan format yang sama seperti sukses agar loop tidak error\n",
        "        return error_msg, chat_history\n",
        "\n",
        "    # --- Membangun Pesan Pengguna Multi-Modal ---\n",
        "    user_message_content_parts = []\n",
        "    # Selalu ada bagian teks\n",
        "    user_message_content_parts.append({\"type\": \"text\", \"text\": user_text_input})\n",
        "\n",
        "    if image_base64_data_uri:\n",
        "        user_message_content_parts.append({\n",
        "            \"type\": \"image_url\",\n",
        "            \"image_url\": {\"url\": image_base64_data_uri}\n",
        "        })\n",
        "        # Tidak perlu display Markdown di sini karena akan ditampilkan di loop utama\n",
        "\n",
        "    # Buat pesan pengguna baru dengan konten multi-modal\n",
        "    new_user_message = {\"role\": \"user\", \"content\": user_message_content_parts}\n",
        "\n",
        "    # Tambahkan pesan pengguna baru ke riwayat\n",
        "    # Perhatian: Riwayat sebelumnya mungkin hanya teks.\n",
        "    # Model seperti gpt-4o bisa menangani campuran ini, tapi ini adalah penyederhanaan.\n",
        "    # Untuk sistem yang lebih canggih, Anda mungkin perlu memproses riwayat gambar juga.\n",
        "    current_chat_history = chat_history + [new_user_message]\n",
        "\n",
        "    try:\n",
        "        # display(Markdown(f\"DEBUG: Mengirim ke model {model_name} dengan pesan: {current_chat_history}\"))\n",
        "        response = client.chat.completions.create(\n",
        "            model=model_name,\n",
        "            messages=current_chat_history, # Kirim riwayat yang sudah diperbarui\n",
        "            max_tokens=500 # Mungkin perlu lebih banyak token untuk deskripsi gambar\n",
        "        )\n",
        "        ai_reply = response.choices[0].message.content\n",
        "\n",
        "        # Tambahkan balasan AI ke riwayat (balasan AI akan selalu teks)\n",
        "        updated_chat_history = current_chat_history + [{\"role\": \"assistant\", \"content\": ai_reply}]\n",
        "\n",
        "        return ai_reply, updated_chat_history # Kembalikan riwayat yang sudah termasuk pesan user & AI terakhir\n",
        "\n",
        "    except openai.APIError as e:\n",
        "        error_message = f\"üò• Maaf, terjadi kesalahan API OpenAI: {e}\"\n",
        "        display(Markdown(f\"<div style='color: red; border: 1px solid red; padding: 10px; border-radius: 5px;'>{error_message}</div>\"))\n",
        "        # Jangan tambahkan pesan error ke riwayat, kembalikan riwayat sebelum panggilan gagal\n",
        "        return error_message, chat_history\n",
        "    except Exception as e:\n",
        "        error_message = f\"ü§Ø Aduh, ada error tak terduga: {e}\"\n",
        "        display(Markdown(f\"<div style='color: red; border: 1px solid red; padding: 10px; border-radius: 5px;'>{error_message}</div>\"))\n",
        "        return error_message, chat_history\n",
        "\n",
        "print(\"‚úÖ Fungsi chat_with_ai_multimodal siap digunakan.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5ufA8gc3VAW",
        "outputId": "60a3c3ba-1c89-4e20-aca2-6486b1a04dba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Fungsi chat_with_ai_multimodal siap digunakan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tahap Bonus B: Loop Interaktif Aplikasi Chat Multi-Modal\n",
        "\n",
        "# --- PASTIKAN IMPOR ADA DI SINI ---\n",
        "from google.colab import files\n",
        "import mimetypes\n",
        "import base64\n",
        "# --- AKHIR BAGIAN IMPOR ---\n",
        "\n",
        "if not client:\n",
        "    display(Markdown(\"üî¥ **Tidak dapat menjalankan chat:** Klien OpenAI belum siap. Pastikan kunci API sudah benar dan klien terinisialisasi.\"))\n",
        "else:\n",
        "    display(Markdown(\"üöÄ **Aplikasi Chat Multi-Modal Siap Dimulai!** üöÄ\"))\n",
        "    print(\"Ketik pesan Anda. Jika ingin menyertakan gambar, jawab 'y' saat ditanya.\")\n",
        "    print(\"Ketik 'exit' atau 'quit' untuk keluar.\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    chosen_model = \"gpt-4o\"\n",
        "    display(Markdown(f\"‚ÑπÔ∏è *Menggunakan model: **{chosen_model}***\"))\n",
        "\n",
        "    chat_history_multimodal = [\n",
        "        {\"role\": \"system\", \"content\": \"Kamu adalah AsistenAI multi-modal yang cerdas dan ramah. Kamu bisa memahami teks dan gambar. Berikan respons yang relevan berdasarkan input yang diberikan.\"}\n",
        "    ]\n",
        "\n",
        "    MAX_HISTORY_TURNS = 10\n",
        "\n",
        "    while True:\n",
        "        current_image_bytes = None\n",
        "        current_image_mime_type = None\n",
        "        image_data_uri_for_api = None # Reset untuk setiap giliran\n",
        "\n",
        "        try:\n",
        "            user_text_input = input(\"üë§ Anda (teks): \")\n",
        "\n",
        "            if user_text_input.lower() in ['exit', 'quit']:\n",
        "                display(Markdown(\"üëã Terima kasih sudah mengobrol! Sampai jumpa lagi!\"))\n",
        "                break\n",
        "\n",
        "            # Cek apakah pengguna ingin mengunggah gambar\n",
        "            ask_for_image = input(\"üñºÔ∏è Ingin menyertakan gambar dengan pesan ini? (y/n, default: n): \").lower().strip()\n",
        "\n",
        "            if ask_for_image == 'y':\n",
        "                display(Markdown(\"üìÇ **Silakan unggah satu file gambar (PNG, JPG, GIF, WEBP):**\"))\n",
        "                # Menggunakan try-except untuk files.upload() karena bisa di-cancel pengguna\n",
        "                try:\n",
        "                    uploaded_image_files = files.upload()\n",
        "                    if uploaded_image_files:\n",
        "                        uploaded_file_name = next(iter(uploaded_image_files))\n",
        "                        current_image_bytes = uploaded_image_files[uploaded_file_name]\n",
        "\n",
        "                        mime_type, _ = mimetypes.guess_type(uploaded_file_name)\n",
        "                        if mime_type and mime_type.startswith(\"image/\"):\n",
        "                            current_image_mime_type = mime_type\n",
        "                            display(Markdown(f\"üëç Gambar '{uploaded_file_name}' (tipe: {current_image_mime_type}) berhasil diunggah.\"))\n",
        "                        else:\n",
        "                            current_image_mime_type = \"image/png\" # Default aman\n",
        "                            display(Markdown(f\"üëç Gambar '{uploaded_file_name}' berhasil diunggah. Tipe MIME tidak terdeteksi, menggunakan default '{current_image_mime_type}'.\"))\n",
        "\n",
        "                        image_data_uri_for_api = image_to_base64(current_image_bytes, current_image_mime_type)\n",
        "                    else:\n",
        "                        display(Markdown(\"‚ö†Ô∏è Tidak ada gambar yang diunggah. Melanjutkan dengan teks saja.\"))\n",
        "                except Exception as e_upload: # Menangkap error jika upload dibatalkan atau gagal\n",
        "                     display(Markdown(f\"‚ÑπÔ∏è Proses unggah gambar dibatalkan atau gagal: {e_upload}. Melanjutkan dengan teks saja.\"))\n",
        "                     current_image_bytes = None # Pastikan ini None jika gagal\n",
        "                     image_data_uri_for_api = None\n",
        "\n",
        "\n",
        "            # Lanjutkan hanya jika ada teks atau gambar yang valid\n",
        "            if not user_text_input.strip() and not image_data_uri_for_api:\n",
        "                display_chat_bubble(\"assistant\", \"Hmm, sepertinya Anda belum mengetik apa-apa atau menyertakan gambar. Ada yang bisa saya bantu?\", chosen_model)\n",
        "                continue\n",
        "\n",
        "            # Tampilkan pesan pengguna (hanya teksnya untuk display bubble standar)\n",
        "            display_chat_bubble(\"user\", user_text_input if user_text_input.strip() else \"(Tidak ada input teks, hanya gambar)\")\n",
        "            if image_data_uri_for_api:\n",
        "                 display(Markdown(f\"üñºÔ∏è *(Gambar disertakan dalam permintaan ke AI)*\"))\n",
        "\n",
        "            ai_response, updated_history = chat_with_ai_multimodal(\n",
        "                user_text_input,\n",
        "                chat_history_multimodal,\n",
        "                image_base64_data_uri=image_data_uri_for_api,\n",
        "                model_name=chosen_model\n",
        "            )\n",
        "            chat_history_multimodal = updated_history\n",
        "\n",
        "            display_chat_bubble(\"assistant\", ai_response, chosen_model)\n",
        "\n",
        "            if len(chat_history_multimodal) > (1 + MAX_HISTORY_TURNS * 2):\n",
        "                display(Markdown(f\"<i>(Riwayat percakapan dipangkas. Menyimpan {MAX_HISTORY_TURNS} interaksi terakhir...)</i>\"))\n",
        "                chat_history_multimodal = [chat_history_multimodal[0]] + chat_history_multimodal[-(MAX_HISTORY_TURNS*2):]\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            display(Markdown(\"\\nüëã Sesi chat dihentikan oleh pengguna. Sampai jumpa!\"))\n",
        "            break\n",
        "        except EOFError:\n",
        "            display(Markdown(\"\\nüëã Input stream berakhir. Sampai jumpa!\"))\n",
        "            break\n",
        "        except Exception as e:\n",
        "            display(Markdown(f\"üö® **Terjadi error pada loop utama chat:** {str(e)}\"))\n",
        "            # Cetak traceback untuk debugging lebih lanjut jika errornya tidak jelas\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            # Pertimbangkan untuk break atau continue tergantung jenis error\n",
        "            # continue\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "    display(Markdown(\"üèÅ **Sesi Chat Multi-Modal Selesai.**\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tvGpHT0-3laS",
        "outputId": "5d587548-586d-4ef9-d84c-1e265843205d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "üöÄ **Aplikasi Chat Multi-Modal Siap Dimulai!** üöÄ"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ketik pesan Anda. Jika ingin menyertakan gambar, jawab 'y' saat ditanya.\n",
            "Ketik 'exit' atau 'quit' untuk keluar.\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "‚ÑπÔ∏è *Menggunakan model: **gpt-4o***"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üë§ Anda (teks): tolong jelaskan gambar apa ini\n",
            "üñºÔ∏è Ingin menyertakan gambar dengan pesan ini? (y/n, default: n): y\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "üìÇ **Silakan unggah satu file gambar (PNG, JPG, GIF, WEBP):**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bfc28fc0-299b-4cca-b559-e7a82b65119c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bfc28fc0-299b-4cca-b559-e7a82b65119c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 8437415341664213099.jpg to 8437415341664213099.jpg\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "üëç Gambar '8437415341664213099.jpg' (tipe: image/jpeg) berhasil diunggah."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n    <div style=\"display: flex; justify-content: flex-start;\">\n        <div style=\"background-color: #E1F5FE; color: #01579B; border-radius: 15px 15px 0 15px; padding: 10px 15px; margin: 5px 50px 5px 5px; max-width: 70%; float: left; clear: both; box-shadow: 2px 2px 5px rgba(0,0,0,0.1);\">\n            <strong style=\"font-size: 0.9em;\">üë§ Anda:</strong><br>\n            tolong jelaskan gambar apa ini\n        </div>\n    </div>\n    <div style=\"clear: both;\"></div>\n    "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "üñºÔ∏è *(Gambar disertakan dalam permintaan ke AI)*"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n    <div style=\"display: flex; justify-content: flex-end;\">\n        <div style=\"background-color: #FCE4EC; color: #880E4F; border-radius: 15px 15px 15px 0; padding: 10px 15px; margin: 5px 5px 5px 50px; max-width: 70%; float: right; clear: both; box-shadow: -2px 2px 5px rgba(0,0,0,0.1);\">\n            <strong style=\"font-size: 0.9em;\">ü§ñ AI (gpt-4o):</strong><br>\n            Gambar ini menunjukkan Monumen Nasional (Monas) yang terletak di Jakarta, Indonesia. Monas merupakan ikon ibu kota yang melambangkan perjuangan kemerdekaan Indonesia. Monumen ini memiliki struktur yang tinggi dengan puncak yang berbentuk lidah api berlapis emas. Di sekitarnya, terlihat latar gedung-gedung tinggi pada malam hari.\n        </div>\n    </div>\n    <div style=\"clear: both;\"></div>\n    "
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üë§ Anda (teks): tolong jelaskan sejarah gambar berikut \n",
            "üñºÔ∏è Ingin menyertakan gambar dengan pesan ini? (y/n, default: n): y\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "üìÇ **Silakan unggah satu file gambar (PNG, JPG, GIF, WEBP):**"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-65382cef-9e32-4453-99ad-bfed962c382e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-65382cef-9e32-4453-99ad-bfed962c382e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 8437415341664213099.jpg to 8437415341664213099 (1).jpg\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "üëç Gambar '8437415341664213099 (1).jpg' (tipe: image/jpeg) berhasil diunggah."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n    <div style=\"display: flex; justify-content: flex-start;\">\n        <div style=\"background-color: #E1F5FE; color: #01579B; border-radius: 15px 15px 0 15px; padding: 10px 15px; margin: 5px 50px 5px 5px; max-width: 70%; float: left; clear: both; box-shadow: 2px 2px 5px rgba(0,0,0,0.1);\">\n            <strong style=\"font-size: 0.9em;\">üë§ Anda:</strong><br>\n            tolong jelaskan sejarah gambar berikut \n        </div>\n    </div>\n    <div style=\"clear: both;\"></div>\n    "
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "üñºÔ∏è *(Gambar disertakan dalam permintaan ke AI)*"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "\n    <div style=\"display: flex; justify-content: flex-end;\">\n        <div style=\"background-color: #FCE4EC; color: #880E4F; border-radius: 15px 15px 15px 0; padding: 10px 15px; margin: 5px 5px 5px 50px; max-width: 70%; float: right; clear: both; box-shadow: -2px 2px 5px rgba(0,0,0,0.1);\">\n            <strong style=\"font-size: 0.9em;\">ü§ñ AI (gpt-4o):</strong><br>\n            Monumen Nasional (Monas) dibangun untuk memperingati perjuangan rakyat Indonesia dalam mencapai kemerdekaan. Peletakan batu pertama dilakukan pada 17 Agustus 1961, di bawah pemerintahan Presiden Soekarno. Monas dirancang oleh arsitek Friedrich Silaban dan R.M. Soedarsono.<br><br>Monas memiliki tinggi 132 meter dan puncaknya dihiasi oleh lidah api berlapis emas. Monumen ini diresmikan pada 12 Juli 1975. Di dalamnya terdapat museum sejarah perjuangan kemerdekaan Indonesia, dan di bagian atasnya terdapat dek observasi yang menawarkan pemandangan Kota Jakarta.<br><br>Monas juga menjadi lokasi berbagai acara penting dan peringatan nasional. Monumen ini merupakan simbol semangat kemerdekaan dan kebanggaan nasional bagi rakyat Indonesia.\n        </div>\n    </div>\n    <div style=\"clear: both;\"></div>\n    "
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üë§ Anda (teks): exit\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "üëã Terima kasih sudah mengobrol! Sampai jumpa lagi!"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "üèÅ **Sesi Chat Multi-Modal Selesai.**"
          },
          "metadata": {}
        }
      ]
    }
  ]
}